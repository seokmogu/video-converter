#!/usr/bin/env python3
import whisper
import openai
import json
import os
from pathlib import Path
import ffmpeg
import textwrap

class ImprovedSubtitleGenerator:
    def __init__(self, openai_api_key=None):
        self.whisper_model = None
        if openai_api_key:
            openai.api_key = openai_api_key
        else:
            print("âš ï¸  OpenAI API í‚¤ê°€ ì—†ì–´ ë²ˆì—­ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    
    def load_whisper_model(self, model_size="large"):
        """Whisper ëª¨ë¸ ë¡œë“œ"""
        print(f"Whisper {model_size} ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.whisper_model = whisper.load_model(model_size)
        print("âœ… Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    def transcribe_japanese_audio(self, video_path, start_time=None, end_time=None):
        """ì¼ë³¸ì–´ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (êµ¬ê°„ ì§€ì • ê°€ëŠ¥)"""
        if not self.whisper_model:
            self.load_whisper_model()
        
        # êµ¬ê°„ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if start_time is not None and end_time is not None:
            print(f"ğŸ¤ ì¼ë³¸ì–´ ìŒì„± ì¸ì‹ ì¤‘ ({start_time}ì´ˆ ~ {end_time}ì´ˆ)...")
            # ì„ì‹œ íŒŒì¼ë¡œ êµ¬ê°„ ì¶”ì¶œ
            temp_audio = "/tmp/temp_segment.wav"
            (
                ffmpeg
                .input(video_path, ss=start_time, t=end_time-start_time)
                .output(temp_audio, acodec='pcm_s16le')
                .overwrite_output()
                .run(capture_stdout=True)
            )
            
            result = self.whisper_model.transcribe(
                temp_audio,
                language="ja",
                word_timestamps=True,
                verbose=True
            )
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°ì • (ì‹œì‘ ì‹œê°„ ì¶”ê°€)
            for segment in result['segments']:
                segment['start'] += start_time
                segment['end'] += start_time
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_audio):
                os.remove(temp_audio)
        else:
            print("ğŸ¤ ì¼ë³¸ì–´ ìŒì„± ì¸ì‹ ì¤‘...")
            result = self.whisper_model.transcribe(
                video_path,
                language="ja",
                word_timestamps=True,
                verbose=True
            )
        
        print(f"âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ: {len(result['segments'])}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        return result
    
    def translate_text_batch(self, texts):
        """ì¼ë³¸ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
        if not openai.api_key:
            print("âš ï¸  OpenAI API í‚¤ê°€ ì—†ì–´ ë²ˆì—­ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return [f"[ë²ˆì—­ í•„ìš”] {text}" for text in texts]
        
        print("ğŸŒ ì¼ë³¸ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­ ì¤‘...")
        
        # ë°°ì¹˜ë¡œ ë²ˆì—­ (ë¹„ìš© ì ˆì•½)
        batch_text = "\n---\n".join(texts)
        
        try:
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ì „ë¬¸ ì¼ë³¸ì–´-í•œêµ­ì–´ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. 
                        AI/ê¸°ìˆ  ê´€ë ¨ ì„¸ë¯¸ë‚˜ ë°œí‘œ ë‚´ìš©ì„ ë²ˆì—­í•©ë‹ˆë‹¤.
                        ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë˜, ê¸°ìˆ  ìš©ì–´ëŠ” ì ì ˆíˆ ìœ ì§€í•˜ì„¸ìš”.
                        ê° ë¬¸ì¥ì€ '---'ë¡œ êµ¬ë¶„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
                        ê°„ê²°í•˜ê³  ì½ê¸° ì‰½ê²Œ ë²ˆì—­í•˜ì„¸ìš”."""
                    },
                    {
                        "role": "user", 
                        "content": f"ë‹¤ìŒ ì¼ë³¸ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”:\n\n{batch_text}"
                    }
                ]
            )
            
            translated_batch = response.choices[0].message.content
            translated_texts = translated_batch.split("\n---\n")
            
            # ì›ë³¸ê³¼ ë²ˆì—­ë³¸ ê°œìˆ˜ ë§ì¶”ê¸°
            if len(translated_texts) != len(texts):
                print("âš ï¸  ë²ˆì—­ ê°œìˆ˜ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. ê°œë³„ ë²ˆì—­ìœ¼ë¡œ ì¬ì‹œë„...")
                return [self.translate_single_text(text) for text in texts]
            
            print(f"âœ… ë²ˆì—­ ì™„ë£Œ: {len(translated_texts)}ê°œ ë¬¸ì¥")
            return translated_texts
            
        except Exception as e:
            print(f"âŒ ë²ˆì—­ ì˜¤ë¥˜: {e}")
            return [f"[ë²ˆì—­ ì‹¤íŒ¨] {text}" for text in texts]
    
    def translate_single_text(self, text):
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ë²ˆì—­"""
        try:
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ì¼ë³¸ì–´ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”."},
                    {"role": "user", "content": text}
                ]
            )
            return response.choices[0].message.content
        except:
            return f"[ë²ˆì—­ ì‹¤íŒ¨] {text}"
    
    def split_long_subtitle(self, text, max_chars=40):
        """ê¸´ ìë§‰ì„ ì—¬ëŸ¬ ì¤„ë¡œ ë¶„í• """
        if len(text) <= max_chars:
            return [text]
        
        # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¶„í•  ì‹œë„
        words = text.split()
        lines = []
        current_line = ""
        
        for word in words:
            if len(current_line + " " + word) <= max_chars:
                current_line += (" " + word) if current_line else word
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        return lines[:3]  # ìµœëŒ€ 3ì¤„ë¡œ ì œí•œ
    
    def create_improved_srt_file(self, segments, translations, output_path):
        """ê°œì„ ëœ SRT ìë§‰ íŒŒì¼ ìƒì„± (í•œêµ­ì–´ë§Œ, ì‘ì€ í°íŠ¸, ê¸´ ìë§‰ ë¶„í• )"""
        print("ğŸ“ ê°œì„ ëœ SRT ìë§‰ íŒŒì¼ ìƒì„± ì¤‘...")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            subtitle_index = 1
            
            for segment, translation in zip(segments, translations):
                # ê¸´ ìë§‰ ë¶„í• 
                lines = self.split_long_subtitle(translation.strip())
                segment_duration = segment['end'] - segment['start']
                
                if len(lines) == 1:
                    # ë‹¨ì¼ ë¼ì¸ ìë§‰
                    start_time = self.seconds_to_srt_time(segment['start'])
                    end_time = self.seconds_to_srt_time(segment['end'])
                    
                    f.write(f"{subtitle_index}\n")
                    f.write(f"{start_time} --> {end_time}\n")
                    f.write(f"{lines[0]}\n\n")
                    subtitle_index += 1
                
                else:
                    # ì—¬ëŸ¬ ë¼ì¸ìœ¼ë¡œ ë¶„í• ëœ ìë§‰
                    line_duration = segment_duration / len(lines)
                    
                    for i, line in enumerate(lines):
                        line_start = segment['start'] + (i * line_duration)
                        line_end = segment['start'] + ((i + 1) * line_duration)
                        
                        start_time = self.seconds_to_srt_time(line_start)
                        end_time = self.seconds_to_srt_time(line_end)
                        
                        f.write(f"{subtitle_index}\n")
                        f.write(f"{start_time} --> {end_time}\n")
                        f.write(f"{line}\n\n")
                        subtitle_index += 1
        
        print(f"âœ… ê°œì„ ëœ SRT íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}")
    
    def seconds_to_srt_time(self, seconds):
        """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    def embed_improved_subtitles_to_video(self, video_path, srt_path, output_path):
        """ê°œì„ ëœ ìë§‰ì„ ë¹„ë””ì˜¤ì— í•˜ë“œì½”ë”© (ì‘ì€ í°íŠ¸, í•œêµ­ì–´ë§Œ)"""
        print("ğŸ¬ ê°œì„ ëœ ìë§‰ì„ ë¹„ë””ì˜¤ì— ì‚½ì… ì¤‘...")
        
        try:
            # ê²½ë¡œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            video_path = str(video_path)
            srt_path = str(srt_path)
            output_path = str(output_path)
            
            # SRT íŒŒì¼ ê²½ë¡œ ì´ìŠ¤ì¼€ì´í”„
            srt_path_escaped = srt_path.replace('\\', '\\\\').replace(':', '\\:')
            
            # ê°œì„ ëœ ìë§‰ ìŠ¤íƒ€ì¼ (ì‘ì€ í°íŠ¸, ê¹”ë”í•œ ë””ìì¸)
            subtitle_filter = f"subtitles='{srt_path_escaped}':force_style='FontSize=14,PrimaryColour=&Hffffff,BackColour=&H80000000,OutlineColour=&H0,BorderStyle=3,MarginV=30'"
            
            (
                ffmpeg
                .input(video_path)
                .output(
                    output_path,
                    vf=subtitle_filter,
                    vcodec='libx264',
                    acodec='aac',
                    crf=20,  # ì¢‹ì€ í’ˆì§ˆ
                    preset='medium'
                )
                .overwrite_output()
                .run(capture_stdout=True, capture_stderr=True)
            )
            
            print(f"âœ… ê°œì„ ëœ ìë§‰ í¬í•¨ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            return True
            
        except ffmpeg.Error as e:
            print(f"âŒ ìë§‰ ì‚½ì… ì‹¤íŒ¨: {e}")
            if e.stderr:
                print(f"FFmpeg ì˜¤ë¥˜ ì„¸ë¶€ ì •ë³´: {e.stderr.decode('utf-8')}")
            return False
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False
    
    def process_video_segment(self, video_path, output_dir=None, start_time=None, end_time=None):
        """ë¹„ë””ì˜¤ êµ¬ê°„ ì²˜ë¦¬ (êµ¬ê°„ ì§€ì • ê°€ëŠ¥)"""
        video_file = Path(video_path)
        if output_dir is None:
            output_dir = video_file.parent
        else:
            output_dir = Path(output_dir)
        
        segment_info = f"_{start_time}s-{end_time}s" if start_time is not None and end_time is not None else ""
        
        print(f"ğŸš€ ê°œì„ ëœ ë¹„ë””ì˜¤ ìë§‰ ìƒì„± ì‹œì‘: {video_file.name}{segment_info}")
        
        # 1. ìŒì„± ì¸ì‹
        transcription = self.transcribe_japanese_audio(video_path, start_time, end_time)
        
        # 2. ë²ˆì—­
        japanese_texts = [segment['text'] for segment in transcription['segments']]
        korean_translations = self.translate_text_batch(japanese_texts)
        
        # 3. ê°œì„ ëœ SRT íŒŒì¼ ìƒì„±
        srt_path = output_dir / f"{video_file.stem}{segment_info}_improved_subtitles.srt"
        self.create_improved_srt_file(transcription['segments'], korean_translations, srt_path)
        
        # 4. ê°œì„ ëœ ìë§‰ í¬í•¨ ë¹„ë””ì˜¤ ìƒì„±
        output_video_path = output_dir / f"{video_file.stem}{segment_info}_improved_subtitles.mp4"
        success = self.embed_improved_subtitles_to_video(video_path, srt_path, output_video_path)
        
        if success:
            print(f"\nğŸ‰ ì™„ë£Œ! ê°œì„ ëœ ìë§‰ í¬í•¨ ë¹„ë””ì˜¤: {output_video_path}")
            return output_video_path
        else:
            print(f"\nğŸ“„ SRT íŒŒì¼ë§Œ ìƒì„±ë¨: {srt_path}")
            return srt_path

def main():
    # OpenAI API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°)
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        print("export OPENAI_API_KEY=your_api_key_here")
        return
    
    # ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš©
    video_path = "/Users/smgu/test_code/video_converter/video.mov"
    
    # ì¤‘ê°„ êµ¬ê°„ 1ë¶„ í…ŒìŠ¤íŠ¸ (30ë¶„~31ë¶„)
    start_time = 30 * 60  # 30ë¶„
    end_time = 31 * 60    # 31ë¶„
    
    print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ êµ¬ê°„: {start_time//60}ë¶„{start_time%60:02d}ì´ˆ ~ {end_time//60}ë¶„{end_time%60:02d}ì´ˆ")
    
    # ê°œì„ ëœ ìë§‰ ìƒì„±ê¸° ì‹¤í–‰
    generator = ImprovedSubtitleGenerator(api_key)
    result = generator.process_video_segment(video_path, start_time=start_time, end_time=end_time)
    
    print(f"\nâœ… ì‘ì—… ì™„ë£Œ: {result}")

if __name__ == "__main__":
    main()